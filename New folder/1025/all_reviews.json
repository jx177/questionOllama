[
  "This paper is about Thai part-of-speech tagging.  It describes a mapping of ORCHID, a Thai-specific POS tagset, to the Universal Dependencies (UD) scheme, and evaluates various state-of-the-art POS taggers on this scheme.  It also compares different subword representation strategies and finds that syllable representations perform best (when not using BERT).\nMain strengths: - Mapping existing Thai corpora to the UD scheme is a useful contribution for Thai NLP, as the UD scheme has become popular for multilingual work, and this will allow Thai NLP to profit better from advances in this area.\n- Syllable segmentation is shown to be advantageous over characters or BPE, suggesting a potential research direction for improving future Thai NLP models.\nMain weaknesses (for each of them, see detailed comments below): - The description of the corpus and the experimental setup frequently lacked some details; there is also no comparison to an existing Thai UD resource.\n- I did not learn much from the evaluation; monolingual BERT achieves the highest accuracy, which by itself is not very surprising nor insightful.\n- The presentation could be improved and distracts from the content at times.\nDetailed comments: - There already is a small UD treebank for Thai: <https://github.com/UniversalDependencies/UD_Thai-PUD/>   How does your mapped tagset compare to the annotation scheme chosen there?  For example, you explained why ADJ is not used in your mapping, but ADJ does appear in this UD treebank.  A comparison and discussion of this would be really useful.\n- You say that \"syllables are generated automatically\". How does this work? Is it possible to split Thai words into syllables without any ambiguity, or do you need a heuristic? Some more detail here would be nice.\n- Since syllables outperformed BPE in the BiLSTM-CRF setup, is there a way to combine syllable information with the BERT models?  For example, have you tried combining syllable-level word representations with BERT representations?\n- Does the ORCHID corpus already provide word segmentation and train/dev/test splits? If yes, make this explicit; if not, how did you produce them?\n- You provide the mapped ORCHID corpus in JSON format in the Supplementary Material. Why did you not use CoNLL-U? This would be much more useful for other researchers as it is the file format used by UD.\n- It would have been interesting to see a comparison of POS tagging performance with UD-style tags versus ORCHID tags. Which one is easier for taggers to learn? When you map ORCHID to UD, you lose information, since the ORCHID tagset is more fine-grained; does this make a big difference for taggers?\nPresentation: - The \"Crime Suppression Division\" example would be clearer if you showed it graphically in a figure. Also, what is the meaning of the two segments of \"suppress\"?\n- Table 1 would be much more readable if you didn't use horizontal lines after every ORCHID tag. Numbers should be right-aligned. Try using horizontal lines only after each UD tag category, and consider the \"booktabs\" guidelines for making good-looking tables. ( https://ctan.math.illinois.edu/macros/latex/contrib/booktabs/booktabs.pdf) - Please pay more attention to your References section. Publication venues are often missing; e.g., where was Boonkwan & Supnithi (2018) published? Also, the citation to Universal Dependencies is completely broken.\n- \u00a72: \"study that implement\" -> \"study that implements\" - \u00a73: \"adjectives has\" -> \"adjectives have\" - \u00a74: \"analyzing sub-component\" -> \"analyzing sub-components\" - \u00a75: \"Syllables features also generally performs\" -> \"Syllable features also generally perform\" ",
  "This paper presents a conversion from a \"traditional\" POS tag set to UD tagset for Thai, and presents POS tagging experiments with a variety of models that differ in two dimensions: (1) the type of sub-word units, and (2) and type of pre-training. The authors conclude that sub-word units are beneficial for the task as well as language-specific pre-training.\nThe problem investigated is a standard problem, but the fact that the paper is on a relatively less-studied language increases the value of the paper. The conversion of a language-specific tagset to a multi-lingual, \"universal\", tagset is interesting, and the methods presented, although standard/straightforward, makes sense. However, the paper leaves many questions unanswered, it should probably be a long paper with further information, analyses and discussion. I will list some of the issues with the paper.\nThe conversion of ORCHID to UD has multiple issues: - First, there is no clear motivation for this conversion.  From Table   1, this seems this is a lossy conversion.  Given that there is not   strong motivation (e.g., creating a UD compliant treebank), the    purpose of the conversion is also unclear, similar to what authors   mean by \"manageable tagset\" (p.1, last paragraph).\n- There is little information on conversion process. It seems there    wasn't enough attention put into the conversion process.  In a   proper conversion to UD, one should also map some of the sub-types   to morphological features.   - The conversion also makes the results incomparable to the earlier   studies on this data set. Irrespective of the comparison to other    studies, it would have been interesting to see the results of the   systems tested with both tagsets. \n   - It is also surprising to see no mention of the existing Thai UD   treebank (Thai PUD). The treebank includes both coarse (UD) and fine    (presumably ORCHID) POS tags. A comparison of conversion used in    this treebank and in the present paper is needed for better   understanding the value of the conversion presented. \n   - Additional information, e.g., tag distribution (before and after   conversion), on the data set would be beneficial for interpretation   of the results discussed. \n   Investigating the effects of use of sub-word units is interesting. \nHowever, I have difficulties interpreting the results for two reasons: - No discussion, or analysis, of the results. We are given a number of   performance metrics, announcement of the best models, and no insight   into why these differences should be observed, or are there anything   contrary to expectations. For example, the failure of multi-lingual   BERT (even in OoV words) needs some explanation discussion. \n  Pre-trained model not only \"does not benefit from the cross lingual   transfer\", but hurts the performance of the model compared much   simpler ones. \n   - The models presented typically have large variation due to effects   like random initialization and test set split. As a result it is   difficult get a good sense of which model is better without having   an indication of how much the results vary. Furthermore, the authors   seem to have missed the fact that in the results they present in    Table 4, syllable-based (not pre-trained) model performs as well as   BERT on in-vocabulary words. \n   In general, given current presentation, I do not think results are conclusive.\nThere are also frequent typos and language mistakes. A thorough  proofreading is recommended. Here are a few examples: - title: \"Pre-trained Language Model\" -> \"Pre-trained Language Models\" - abstract: \"syllables representations\" -> \"syllable representations\" - Intro, paragraph  1: \"Modern approaches include\" -> \"Modern approaches includes\" - In general quite a few agreement mistakes, a through proofreading   would be good.\n- Intro, paragraph  1: multiple citations should be placed in a single   pair of parentheses, and citations should not be after the sentence final   punctuation.\n- 'related work', paragraph 1 (and other places): when using a   citation as part of the sentence, it should not be in parentheses. \n  \"(Akbik et al., 2018) proposed\" -> \"Akbik et al. (2018) proposed\"   (see conference style/guidelines for more information) - Most tables are not referenced from the main text. The reader needs   to know what to look at in those tables, and in what way they   support the description or argumentation.\n- There are proper names or abbreviations in the references (likely   BibTeX normalization issues): \"thai\", \"bilstm\", ... "
]