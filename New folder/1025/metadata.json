{"authors": null, "title": "Subword Representations and Pre-trained Language Model for Thai Part-of-Speech Tagging in Universal Part of Speech Scheme", "abstract": "Part-of-speech tagging is a crucial step for many downstream tasks; yet, it is understudied for Thai text. Thai words can be composed by a few subwords, which have their own meanings, despite being an isolating language. Therefore, subword representation should provide helpful cues for POS tagging in Thai. We mapped the Thai-specific ORCHID tag set to the multilingual applicable Universal Dependency tag set and experiment with character, syllable, and byte-pair encoding (BPE) as subword features which can form word embeddings consumed by taggers. Our results reveal that syllables representations are better than word and character embeddings for Thai POS tagging, especially for handling out of vocabulary words. And BERT models, which use BPE and pretrained language models, yield the state-of-the art results.", "track": "Tag-Chunk-SyntaxParsing", "status": "Reject", "type": "Short paper"}